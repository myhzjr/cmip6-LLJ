{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manuelhernandez/opt/miniconda3/lib/python3.7/site-packages/tqdm/autonotebook.py:17: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import xskillscore as xs\n",
    "import xesmf as xe\n",
    "from tqdm.autonotebook import tqdm  # Fancy progress bars for our loops!\n",
    "import intake\n",
    "import util \n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 12, 6\n",
    "%config InlineBackend.figure_format = 'retina' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict = {}\n",
    "col = intake.open_esm_datastore(\"../catalogs/pangeo-cmip6.json\")\n",
    "\n",
    "import pprint\n",
    "uni_dict = col.unique(['source_id','experiment_id','table_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose how much to coarsen data\n",
    "coarsen_size = 2\n",
    "\n",
    "# Define the common target grid axes\n",
    "dlon, dlat = 1., 1.\n",
    "ds_out = xr.Dataset({'lat': (['lat'], np.arange(-90.+dlat/2., 90., dlat)),\n",
    "                     'lon': (['lon'], np.arange(0.+dlon/2., 360., dlon)),})\n",
    "\n",
    "# Regridding function\n",
    "def regrid_to_common(ds, ds_out):\n",
    "    \"\"\"\n",
    "    Regrid from rectilinear grid to common grid\n",
    "    \"\"\"\n",
    "    regridder = xe.Regridder(ds, ds_out, 'bilinear',periodic=True, reuse_weights=True)\n",
    "    return regridder(ds)\n",
    "\n",
    "Rearth = 6.378E6   # radius of Earth in meters\n",
    "# a DataArray that gives grid cell areas on the lat/lon grid (in units of m^2)\n",
    "area = (np.deg2rad(dlat)*Rearth) * (np.deg2rad(dlon)*Rearth*np.cos(np.deg2rad(ds_out.lat))) * xr.ones_like(ds_out.lon)\n",
    "\n",
    "# coarsen\n",
    "area = area.coarsen({'lat': coarsen_size, 'lon': coarsen_size}, boundary='exact').mean()\n",
    "\n",
    "# month lengths\n",
    "days_in_month = np.array([31 , 28.25, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31])\n",
    "days_in_month = xr.DataArray(days_in_month, coords=[np.arange(1,13,1)], dims=['month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "\n",
      "--> There will be 11 group(s)\n"
     ]
    }
   ],
   "source": [
    "models = set(uni_dict['source_id']['values']) # all the models\n",
    "for experiment_id in ['historical', 'ssp585','ssp370']:\n",
    "    query = dict(experiment_id=experiment_id, table_id='Amon',\n",
    "                 variable_id='va', grid_label='gn')  \n",
    "    cat = col.search(**query)\n",
    "    models = models.intersection({model for model in cat.df.source_id.unique().tolist()})\n",
    "models = list(models)\n",
    "models\n",
    "cat = col.search(experiment_id=['historical'], table_id='Amon',\n",
    "                 variable_id='va', grid_label='gn', source_id=models)   \n",
    "dset_dict = cat.to_dataset_dict(zarr_kwargs={'consolidated': True, 'decode_times': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slice = slice('1950','2014')\n",
    "plev_slice = 85000\n",
    "lat_bnds  = [27.5,42.5]\n",
    "lon_bnds  = [257.5,270]\n",
    "region = dict(lat=slice(27.5,42.5),lon=slice(257.5,270))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a78729b9fdc468e8bc3fd7fe4eeff41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manuelhernandez/opt/miniconda3/lib/python3.7/site-packages/xarray/core/indexing.py:1311: PerformanceWarning: Slicing with an out-of-order index is generating 165 times more chunks\n",
      "  return self.array[key]\n",
      "/Users/manuelhernandez/opt/miniconda3/lib/python3.7/site-packages/xarray/core/indexing.py:1311: PerformanceWarning: Slicing with an out-of-order index is generating 165 times more chunks\n",
      "  return self.array[key]\n",
      "/Users/manuelhernandez/opt/miniconda3/lib/python3.7/site-packages/xarray/core/indexing.py:1311: PerformanceWarning: Slicing with an out-of-order index is generating 167 times more chunks\n",
      "  return self.array[key]\n",
      "/Users/manuelhernandez/opt/miniconda3/lib/python3.7/site-packages/xarray/core/indexing.py:1311: PerformanceWarning: Slicing with an out-of-order index is generating 165 times more chunks\n",
      "  return self.array[key]\n",
      "/Users/manuelhernandez/opt/miniconda3/lib/python3.7/site-packages/xarray/core/indexing.py:1311: PerformanceWarning: Slicing with an out-of-order index is generating 165 times more chunks\n",
      "  return self.array[key]\n",
      "/Users/manuelhernandez/opt/miniconda3/lib/python3.7/site-packages/xarray/core/indexing.py:1311: PerformanceWarning: Slicing with an out-of-order index is generating 165 times more chunks\n",
      "  return self.array[key]\n",
      "/Users/manuelhernandez/opt/miniconda3/lib/python3.7/site-packages/xarray/core/indexing.py:1311: PerformanceWarning: Slicing with an out-of-order index is generating 165 times more chunks\n",
      "  return self.array[key]\n",
      "/Users/manuelhernandez/opt/miniconda3/lib/python3.7/site-packages/xarray/core/indexing.py:1311: PerformanceWarning: Slicing with an out-of-order index is generating 165 times more chunks\n",
      "  return self.array[key]\n",
      "/Users/manuelhernandez/opt/miniconda3/lib/python3.7/site-packages/xarray/core/indexing.py:1311: PerformanceWarning: Slicing with an out-of-order index is generating 165 times more chunks\n",
      "  return self.array[key]\n",
      "/Users/manuelhernandez/opt/miniconda3/lib/python3.7/site-packages/xarray/core/indexing.py:1311: PerformanceWarning: Slicing with an out-of-order index is generating 165 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manuelhernandez/opt/miniconda3/lib/python3.7/site-packages/xarray/core/indexing.py:1311: PerformanceWarning: Slicing with an out-of-order index is generating 165 times more chunks\n",
      "  return self.array[key]\n"
     ]
    }
   ],
   "source": [
    "ds_dict = {}\n",
    "va_dict = {}\n",
    "for name, ds in tqdm(dset_dict.items()):\n",
    "    if ('latitude' in ds.dims) and ('longitude'in ds.dims):\n",
    "        ds = ds.rename({'latitude':'lat', 'longitude':'lon'}) #Some Models Labeled Differently\n",
    "    ds = xr.decode_cf(ds)\n",
    "    ds = (ds.mean(dim='member_id'))\n",
    "    ds = ds.sel(plev=plev_slice)\n",
    "    \n",
    "    # drop redundant variables (like \"height: 2m\")\n",
    "    for coord in ds.coords:\n",
    "        if coord not in ['lat','lon','time']:\n",
    "            ds = ds.drop(coord)\n",
    "            \n",
    "            \n",
    "    va_clim = ds.groupby('time.month').mean('time')\n",
    "    va_anom = ds.groupby('time.month') - va_clim\n",
    "    va_anom = va_anom - va_anom.sel(time=slice('1970','2000')).mean(dim='time')\n",
    "    ds_con = va_anom.sel(**region)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## Calculate global-mean meridional wind\n",
    "    #cos_lat_2d = np.cos(np.deg2rad(ds['lat'])) * xr.ones_like(ds['lon']) # effective area weights\n",
    "    #va = (\n",
    "    #    (ds['va'] * cos_lat_2d).sum(dim=['lat','lon']) /\n",
    "    #    cos_lat_2d.sum(dim=['lat','lon'])\n",
    "    #    )\n",
    "    \n",
    "    #va_dict[name] = va.squeeze()\n",
    "    #ds_dict[name] = ds\n",
    "   # monClim = ds.sel(time=time_slice).groupby('time.month').mean(dim='time')\n",
    "    \n",
    "\n",
    "    #ds = (ds.sel(time=time_slice).groupby('time.month').mean(dim='time') -\n",
    "    #        ds.sel(time=time_slice).mean(dim='time'))\n",
    "\n",
    "#    ds_new = regrid_to_common(clim['va'],ds_out)\n",
    "\n",
    "    # Maybe chance this at pre-processing stage?\n",
    "    #ds.attrs['name'] = ds.attrs['institution']\n",
    "    \n",
    "    #Add Ensemble as a New Dimension\n",
    "    #ds = ds.expand_dims({'ensemble': np.array([ds.attrs['name']])},0)\n",
    "               \n",
    "\n",
    "    # We should keep the metadata!\n",
    "#   ds_new = ds_new.coarsen({'lat':coarsen_size, 'lon':coarsen_size}, boundary='exact').mean()   \n",
    "\n",
    "    # Add this to the dictionary\n",
    "    #ds_dict[name] = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (bnds: 2, lat: 7, lon: 4, time: 1980)\n",
       "Coordinates:\n",
       "  * lon        (lon) float64 258.8 262.5 266.2 270.0\n",
       "  * lat        (lat) float64 27.95 30.19 32.42 34.66 36.89 39.13 41.37\n",
       "  * time       (time) object 1850-01-17 00:00:00 ... 2014-12-17 00:00:00\n",
       "    month      (time) int64 1 2 3 4 5 6 7 8 9 10 11 ... 2 3 4 5 6 7 8 9 10 11 12\n",
       "Dimensions without coordinates: bnds\n",
       "Data variables:\n",
       "    areacella  (time, lat, lon) float64 dask.array<chunksize=(1, 7, 4), meta=np.ndarray>\n",
       "    lat_bnds   (time, lat, bnds) float64 dask.array<chunksize=(1, 7, 2), meta=np.ndarray>\n",
       "    lon_bnds   (time, lon, bnds) float64 dask.array<chunksize=(1, 4, 2), meta=np.ndarray>\n",
       "    va         (time, lat, lon) float32 dask.array<chunksize=(1, 7, 4), meta=np.ndarray>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_con"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
